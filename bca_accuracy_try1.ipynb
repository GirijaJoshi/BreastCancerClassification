{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting names of all the files in IDC_regular_ps50_idx5and sub dirs\n",
    "files = glob('Resources/IDC_regular_ps50_idx5/*/*/*')\n",
    "\n",
    "# Example : Resources/IDC_regular_ps50_idx5\\\\10254\\\\0\\\\10254_idx5_x1001_y1001_class0.png'\n",
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # checking how many are cancer files which has class1 in it\n",
    "count =0 \n",
    "for file in files:\n",
    "    # print(f'-5:{file[-5]}')\n",
    "    if file[-5] == '1':\n",
    "        count+=1\n",
    "\n",
    "print(f'Number Of 1: {count}')\n",
    "print(f'Number Of 0: {len(files) - count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of files\n",
    "print(f'Total: {len(files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y train data\n",
    "# This function takes input start and end value for reading the images\n",
    "def find_data(files, lower_limit, upper_limit):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # tqdm(patient_ids)\n",
    "    for file in tqdm(files[lower_limit:upper_limit]):\n",
    "        if file.endswith(\".png\"):\n",
    "            # Convering cureent image into PIL image format. PIL image format is RGB format.\n",
    "            img = tf.keras.preprocessing.image.load_img(file, target_size = (50,50))\n",
    "            \n",
    "            # Keras provides the img_to_array() function for converting a loaded image in PIL format into a NumPy array \n",
    "            #for use with deep learning models. The image is convertated into t [height, width, channels]\n",
    "\n",
    "            # # Arguments\n",
    "            #         img: PIL Image instance.\n",
    "            #         data_format: Image data format,\n",
    "            #             either \"channels_first\" or \"channels_last\".\n",
    "            #         dtype: Dtype to use for the returned array.\n",
    "            # Returns: A 3D Numpy array.\n",
    "            \n",
    "            # The component values are often stored as integer numbers in the range 0 to 255, \n",
    "            # the range that a single 8-bit byte can offer,\n",
    "            pixels = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            \n",
    "            # converting into 0 - 1, This is called as Normalization will help you to remove distortions \n",
    "            # caused by lights and shadows in an image.\n",
    "            pixels /= 255\n",
    "            X.append(pixels)\n",
    "            if(file[-5] == '1'):\n",
    "                y.append(1)\n",
    "            elif(file[-5] == '0'):\n",
    "                y.append(0)\n",
    "    return np.stack(X), y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = find_data(files,0, 90000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test data\n",
    "X_test, y_test = find_data(files, 90000, 110000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_data(files, size, start_index):\n",
    "    half_size = int(size/2)\n",
    "    count=0\n",
    "    res = []\n",
    "    y = []\n",
    "    for file in tqdm(files[start_index:]):\n",
    "        if (count!=half_size):\n",
    "            if file[-5] == '1' and file.endswith(\".png\"):\n",
    "                img = tf.keras.preprocessing.image.load_img(file, target_size = (50,50))\n",
    "                pixels = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                pixels /= 255\n",
    "                res.append(pixels)\n",
    "                y.append(1)\n",
    "                count += 1\n",
    "                \n",
    "    for file in tqdm(files[start_index:]):\n",
    "        if(count!=0):\n",
    "            if(file[-5] == '0'):\n",
    "                img = tf.keras.preprocessing.image.load_img(file, target_size = (50,50))\n",
    "                pixels = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                pixels /= 255\n",
    "                res.append(pixels)\n",
    "                y.append(0)\n",
    "                count -= 1\n",
    "    return np.stack(res), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, y_train2 = balanced_data(files, 90000,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test2, y_test2 = balanced_data(files, 20000, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train2 is 4 diemtion we need to convert in 2D\n",
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, Activation, MaxPooling2D, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_model(inp_shape = (50,50,3)):\n",
    "    inp = Input(inp_shape)\n",
    "    m = Conv2D(32, (3,3), kernel_initializer='he_uniform', padding=\"same\", activation='relu')(inp)\n",
    "    m = MaxPooling2D(2)(m)\n",
    "    # m = BatchNormalization()(m)\n",
    "    \n",
    "    m = Conv2D(64, (3,3), kernel_initializer='he_uniform', padding=\"same\", activation='relu')(m)\n",
    "    m = MaxPooling2D(2)(m)\n",
    "    # m = BatchNormalization()(m)\n",
    "    \n",
    "    m = Conv2D(128, (3,3), kernel_initializer='he_uniform', padding=\"same\", activation='relu')(m)\n",
    "    m = MaxPooling2D(2)(m)\n",
    "    \n",
    "    m = Conv2D(128, (3,3), kernel_initializer='he_uniform', padding=\"same\", activation='relu')(m)\n",
    "    m = MaxPooling2D(2)(m)\n",
    "    \n",
    "    \n",
    "    m = Conv2D(256, (3,3), kernel_initializer='he_uniform', padding=\"same\", activation='relu')(m)\n",
    "    m = MaxPooling2D(2)(m)\n",
    "    \n",
    "    # m = BatchNormalization()(m)\n",
    "    \n",
    "    # m = MaxPooling2D(2)(m)\n",
    "    m = Flatten()(m)\n",
    "    \n",
    "    m = Dense(128, activation = \"relu\")(m)\n",
    "    out = Dense(1, activation = \"sigmoid\")(m)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer = keras.optimizers.SGD(1e-3, momentum=0.9), loss=\"binary_crossentropy\", metrics = ['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = form_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train2, y_train2, validation_data=(x_test2, y_test2), epochs = 25, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating and printing results \n",
    "score = model.evaluate(x_test, y_test, verbose = 0) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(height_shift_range=0.2,\n",
    "                            width_shift_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            shear_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow(X_train2, y_train2, batch_size=256)\n",
    "val_generator = datagen.flow(x_test2, y_test2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(train_generator, validation_data=val_generator, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for prediction in pred:\n",
    "    if(prediction > 0.5):\n",
    "        res.append(1)\n",
    "    else:\n",
    "        res.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test2, res))\n",
    "print(classification_report(y_test2, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
