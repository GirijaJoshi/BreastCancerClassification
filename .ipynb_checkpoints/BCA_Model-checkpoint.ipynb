{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting names of all the files in IDC_regular_ps50_idx5and sub dirs\n",
    "print(\"Please wait getting all images.....\")\n",
    "# files = glob('Resources/IDC_regular_ps50_idx5/*/*/*')\n",
    "files = glob('resources\\equal_images/*/*/*')\n",
    "# files = glob('C:\\BootCamp\\BreastCancerClassification\\equal_images/8863/*/*')\n",
    "\n",
    "# Example : Resources/IDC_regular_ps50_idx5\\\\10254\\\\0\\\\10254_idx5_x1001_y1001_class0.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many are cancer files which has class1 in it\n",
    "count =0 \n",
    "for file in files:\n",
    "    if 'class1' in file:\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('------------------')\n",
    "\n",
    "print(f'Number Of 1: {count}')\n",
    "print(f'Number Of 0: {len(files) - count}')\n",
    "# total number of files\n",
    "print(f'Total: {len(files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = os.path.join('Users/harrisonpreston/Google_Drive/Data_Analytics_Bootcamp/Module_20/BreastCancerClassification/resources/equal_images' + '/10272/1')\n",
    "print(\"Cancer Images\")\n",
    "# print(path)\n",
    "#Plotting the generated images\n",
    "imgs = os.listdir(path)\n",
    "\n",
    "_, axs = plt.subplots(5, 5, figsize=(10, 10))\n",
    "axs = axs.flatten()\n",
    "for img, ax in zip(imgs, axs):\n",
    "    img = plt.imread(path + '/' + img)\n",
    "    ax.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = os.path.join('Users/harrisonpreston/Google_Drive/Data_Analytics_Bootcamp/Module_20/BreastCancerClassification/resources/equal_images' + '/10272/0')\n",
    "print('Non Cancer Images')\n",
    "#Plotting the generated images\n",
    "imgs = os.listdir(path)\n",
    "\n",
    "_, axs = plt.subplots(5, 5, figsize=(10, 10))\n",
    "axs = axs.flatten()\n",
    "for img, ax in zip(imgs, axs):\n",
    "    img = plt.imread(path + '/' + img)\n",
    "    ax.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 80% of total for training and 20% for testing\n",
    "train_num = int(len(files) * 0.80)\n",
    "test_num = len(files) - train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create X and y train data\n",
    "def find_data(files, lower_limit, upper_limit):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # tqdm(patient_ids)\n",
    "    for file in tqdm(files[lower_limit:upper_limit]):\n",
    "        if file.endswith(\".png\"):\n",
    "            # Convering cureent image into PIL image format. PIL image format is RGB format.\n",
    "            img = tf.keras.preprocessing.image.load_img(file, target_size = (50,50))\n",
    "\n",
    "            # Keras provides the img_to_array() function for converting a loaded image in PIL format into a NumPy array \n",
    "            #for use with deep learning models. The image is convertated into t [height, width, channels]\n",
    "\n",
    "            # # Arguments\n",
    "            #         img: PIL Image instance.\n",
    "            #         data_format: Image data format,\n",
    "            #             either \"channels_first\" or \"channels_last\".\n",
    "            #         dtype: Dtype to use for the returned array.\n",
    "            # Returns: A 3D Numpy array.\n",
    "            \n",
    "            # The component values are often stored as integer numbers in the range 0 to 255, \n",
    "            # the range that a single 8-bit byte can offer,\n",
    "            pixels = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "            # converting into 0 - 1, This is called as Normalization will help you to remove distortions \n",
    "            # caused by lights and shadows in an image.\n",
    "            pixels /= 255\n",
    "            X.append(pixels)\n",
    "            if 'class1' in file:\n",
    "                y.append(1)\n",
    "            elif 'class0' in file:\n",
    "                y.append(0)\n",
    "    return np.stack(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Num of training files: {train_num}\\nNum of test files:{test_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = find_data(files,0, train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = find_data(files, train_num, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, Activation, MaxPooling2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train2 is 4 diemtion we need to convert in 2D\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp_shape = (50,50,3)\n",
    "model = Sequential([\n",
    "    # Conv2D(kernel_size=3, filters=16, padding='same', activation='relu', input_shape=[IMG_SIZE,IMG_SIZE, 3]),\n",
    "    Conv2D(32, (3,3), kernel_initializer='he_uniform', padding=\"same\", activation='relu', input_shape=inp_shape),\n",
    "    MaxPooling2D(2),\n",
    "    Conv2D(64, (3,3), kernel_initializer='he_uniform', padding=\"same\", activation='relu'),\n",
    "    MaxPooling2D(2),\n",
    "    Conv2D(128, (3,3), kernel_initializer='he_uniform', padding=\"same\", activation='relu'),\n",
    "    MaxPooling2D(2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation = \"relu\"),\n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilation\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(optimizer = keras.optimizers.SGD(1e-3, momentum=0.9), loss=\"binary_crossentropy\", metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 25, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating and printing results \n",
    "score = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('bca.h5')\n",
    "# model.save_weights('bca_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model.predict(X_test)\n",
    "batch_holder = loaded_model.predict_classes(X_test)\n",
    "\n",
    "res = []\n",
    "for prediction in batch_holder:\n",
    "    if(prediction > 0.5):\n",
    "        res.append(1)\n",
    "    else:\n",
    "        res.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, res))\n",
    "print(classification_report(y_test, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
